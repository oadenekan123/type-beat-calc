# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoBkZvTGnvZtfBFIkOlpc18RD-6m9FXW

The dataset being used for initial analysis can be found here: http://millionsongdataset.com/pages/getting-dataset/#subset

It's a 1.8 GB subset of the MillionSongDataSet. We will be doing some preliminary feature analysis to get an idea of what the data we have looks like.
"""

# Necessary Imports.
#%% importing things
import h5py
import pandas as pd
import pydrive

# Mount Google Drive. Currently the subset is stored on a shared Google Drive Folder.
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
#%% load data


gauth = GoogleAuth()
gauth.LocalWebserverAuth() # client_secrets.json need to be in the same directory as the script
drive = GoogleDrive(gauth)


from google.colab import drive
drive.mount('/content/drive')

filepath = '/content/drive/My Drive/TYPE BEAT CALC/MillionSongSubset/A/R/A/TRARAAG128F42437FB.h5'

f = h5py.File(filepath, 'r')

#%% idk
list(f.keys())
analysis = f['analysis']
metadata = f['metadata']
musicbrainz = f['musicbrainz']

#%% printing shit
print('Analysis Keys')
for k in analysis.keys():
  print(k)

print('\nMetadata Keys')
for k in metadata.keys():
  print(k)

print('\nMusicBrainz Keys')
for k in musicbrainz.keys():
  print(k)

metadata['songs'].attrs